# 2025-08-26

I could connect to dev server via http://192.168.0.177:5173/ when I ran it in
Git for Windows, but I couldn't on WSL with the same URL.

So I followed this guide:

  https://medium.com/codemonday/access-wsl-localhost-from-lan-for-mobile-testing-8635697f008

I made an inbound rule for ports 3000, 4173, and 5173 in firewall. And run the
following command as admin to port forward to WSL.

```
netsh interface portproxy add v4tov4 listenport=5173 listenaddress=0.0.0.0 \
  connectport=5173 connectaddress=172.21.200.192
```

I could see all port forwarding by `netsh interface portproxy dump`.

Basically, distros on WSL2 run in containers and share the same IP. So `ip addr
show eth0` would give the same result.

# 2025-08-22

There are two ids in plans table: `plan_id`, and `partner_plan_id`.
`partner_plan_id` is the primary key of `plans` table. I guess `plan_id` was the
old primary key and `partner_plan_id` has been newly introduced.

```
mysql> select name, description, plan_id, partner_plan_id from plans order by name;
+--------------------+---------------------+--------------------------+---------------------------+
| name               | description         | plan_id                  | partner_plan_id           |
+--------------------+---------------------+--------------------------+---------------------------+
| z-launcher         | z-launcher          | pl-BRcF1-7g6Lg2fxVaR865C | ppl-cGQET06LPIACk8gbpS7P_ |
| z-maya             | Personal monthly    | pl-VpAJUJCbfkv1TdbSIIjvK | 856956                    |
| z-maya             | Personal yearly     | pl-VpAJUJCbfkv1TdbSIIjvK | 856957                    |
| z-maya             | Enterprise yearly   | pl-VpAJUJCbfkv1TdbSIIjvK | 856958                    |
| z-maya Pro         | monthly             | pl-VpAJUJCbfkv1TdbSIIjvK | 825074                    |
| z-maya Pro         | yearly              | pl-VpAJUJCbfkv1TdbSIIjvK | 825075                    |
| z-maya Pro         | Enterprise yearly   | pl-VpAJUJCbfkv1TdbSIIjvK | 826649                    |
| z-maya Pro         | Evaluation          | pl-VpAJUJCbfkv1TdbSIIjvK | ppl-Ue_g5hmFFKti8kyMrA5jq |
| z-maya Pro         | Evaluation          | pl-VpAJUJCbfkv1TdbSIIjvK | ppl-ylrjfeRDVjP7Rsw5TZg0t |
| z-maya Pro         | Evaluation          | pl-VpAJUJCbfkv1TdbSIIjvK | ppl-11AmdScELL4IcHJKD-wui |
| z-maya Pro         | Beta                | pl-VpAJUJCbfkv1TdbSIIjvK | ppl-VfsWyynF5eo-wj3wKGxkO |
| z-unreal           | Evaluation          | pl-jEkf364vnTJy23_vlGAVU | ppl-Fv-yjFPYL0NbAsuaPl03W |
| z-unreal           | Evaluation          | pl-jEkf364vnTJy23_vlGAVU | ppl-gzsYovUs-Fq8-14QffHJd |
| z-unreal           | Evaluation          | pl-jEkf364vnTJy23_vlGAVU | ppl-jmv-b0Xh4D3IMu0-D4roV |
| z-unreal           | Enterprise yearly   | pl-jEkf364vnTJy23_vlGAVU | ppl-rIPNEzC3FbLhGclkMjhio |
| z-unreal           | Enterprise yearly   | pl-jEkf364vnTJy23_vlGAVU | 856961                    |
| z-unreal           | Personal monthly    | pl-jEkf364vnTJy23_vlGAVU | 856959                    |
| z-unreal Personal  | yearly              | pl-jEkf364vnTJy23_vlGAVU | 856960                    |
| z-weave Enterprise | Business            | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-DSWLldogIsS-0y7D1yvvE |
| z-weave Enterprise | Education           | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-44VoPU_GUCnO4aYF7Vyt3 |
| z-weave Enterprise | Evaludation Audaces | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-bt8lKvD1cLb9R6w843g03 |
| z-weave Enterprise | Business            | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-JPowp79tqgd4Fom_ANQVn |
| z-weave Enterprise | Business            | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-UC7x0Mx9eEnQgwIsY1NRh |
| z-weave Enterprise | Evaluation          | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-UccFcBrPd6lMjqKB2w5Cf |
| z-weave Enterprise | Evaluation          | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-vk3R2CXCcjBnguVz8LRz_ |
| z-weave Enterprise | Evaluation          | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-a-prmHxU8YcGYGFYQ47KX |
| z-weave Enterprise | Education           | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-35zQZPLAhBXtOo4nm8YC2 |
| z-weave Enterprise | Evaludation Audaces | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-YqHM2SkRrrwbiOKPLTNHv |
| z-weave Enterprise | Evaluation          | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-zx6jHAudYZswbPEinEudu |
| z-weave Enterprise | Evaluation          | pl-tLAgi7MGeYQq0lVRdzHMn | ppl-_orD3ilYgeWToZ31yF4BQ |
| z-weave Free       |                     | pl-MjinkCdl3lQQk1zlETus5 | ppl-aWCdm7QdkQwaQ7-X7y6MW |
| z-weave Pro        | Evaluation          | pl-4V2WgYhdYKaEHxUAf-97B | ppl-4h8Ysod1evqtGh6TGoByx |
| z-weave Pro        | Evaluation          | pl-4V2WgYhdYKaEHxUAf-97B | ppl-2O4bEcRQ7Ex0UjMZqAcpK |
| z-weave Pro        | Individual          | pl-4V2WgYhdYKaEHxUAf-97B | 884136                    |
| z-weave Pro        | Individual          | pl-4V2WgYhdYKaEHxUAf-97B | 884135                    |
| z-weave Pro        | Evaluation          | pl-4V2WgYhdYKaEHxUAf-97B | ppl-uqxtlfNkSNcb8kzPTPG5r |
| zeavric Free       |                     | pl-p13UG7rnFEh5HEU4WX18I | ppl-4r88PGI_9Yqwp8247m9go |
| zeavric Pro        | Beta                | pl-kn_iGNzxHQjTY1MK0VKns | ppl-AhEHl79bukq4pyz4ryDHS |
| zeavric Pro        | Evaluation          | pl-kn_iGNzxHQjTY1MK0VKns | ppl-SD5o3CJGoq_FUBTiTeVf8 |
| zeavric Pro        | Evaluation          | pl-kn_iGNzxHQjTY1MK0VKns | ppl-RtdnVHvX5KiIn1rQ86XRc |
| zeavric Pro        | Evaluation          | pl-kn_iGNzxHQjTY1MK0VKns | ppl-NZDL9jt81Ud_AmLaooAgu |
| zeavric Pro        | monthly             | pl-kn_iGNzxHQjTY1MK0VKns | 825070                    |
| zeavric Pro        | Personal yearly     | pl-kn_iGNzxHQjTY1MK0VKns | 856955                    |
| zeavric Pro        | Personal monthly    | pl-kn_iGNzxHQjTY1MK0VKns | 856953                    |
| zeavric Pro        | Enterprise yearly   | pl-kn_iGNzxHQjTY1MK0VKns | 826648                    |
| zeavric Pro        | yearly              | pl-kn_iGNzxHQjTY1MK0VKns | 825071                    |
+--------------------+---------------------+--------------------------+---------------------------+
```

They share the same product name if they have the same `plan_id` even thought
they can have different suffices like 'Pro' or 'Enterprise'.


Interestingly, there is a `partner_plan_id` and `plan_id` mistch between subscriptns and plans.

```
select p.plan_id, s.plan_id, s.partner_plan_id, s.start_date, s.end_date from subscriptions s
join plans p on s.partner_plan_id = p.partner_plan_id
where s.plan_id != p.plan_id;

+--------------------------+--------------------------+-----------------+-------------------------+-------------------------+
| plan_id                  | plan_id                  | partner_plan_id | start_date              | end_date                |
+--------------------------+--------------------------+-----------------+-------------------------+-------------------------+
| pl-kn_iGNzxHQjTY1MK0VKns | pl-tLAgi7MGeYQq0lVRdzHMn | 856953          | 2024-07-03 00:53:06.000 | 2024-07-03 00:00:00.000 |
+--------------------------+--------------------------+-----------------+-------------------------+-------------------------+
```

I think this is dead data.


# 2025-08-21

Logging in with Google doesn't work.

When I click the "Continue with Google" in sign-in page, it redirects the page
to https://z-emotion.com/en/sign-in?error=40100&email=netionics%40gmail.com and
says "Please check your ID or Password was incorrect".

In sign-up page, I clicked the "Sign in as 태민", Google login popup window
showed up and I got "Uncaught (in promise) ReferenceError: jwt_decode is not
defined" error.

It looks like jwt-decode was accidently removed by commit 30414e9 ("UI: update
favicon and logo", 2025-05-27) leaving the reference to it. And Webpack
generated the following error:

```
./src/containers/SignUpForm/SSOSignup.js
Module not found: Can't resolve 'jwt-decode' in '/home/kyle/workspace/cloud-ze-frontend/src/containers/SignUpForm'
```

Commit 752937d ("fix: build error", 2025-05-27) removed the import statment to
resolve Webpack error. That's how jwt_decode undefined error occurred.

# 2025-08-20

I connected to zemotion production database via:

```
# Open a tunnel which starts from localhost:3307 and ends to the EC2 instance
# called ssh-tunnel-ze-db(3.36.83.177) which can connect to the database through
# mysql protocol
ssh -i ~/secrets/zw-license-key.pem -L 3307:zemotion-database-cluster.cluster-ro-cwp5bxv53k7w.ap-northeast-2.rds.amazonaws.com:3306 -N ec2-user@3.36.83.177
```

```
# And connect to the localhost:3307 from the another terminal
mysql -h 127.0.0.1 -P 3307 -u admin -p
```

ssh -L makes a tunnel to the real server and every packets that are sent to that
tunnel are forwarded to the server.

# 2025-08-18

I created a AWS Lambda named HyosungVisitor and an API gateway being attached to
it. AWS Lambda gave me a single JS code named index.mjs. I needed to import NPM
packages which means I need package.json, package-local.json, node_modules, and
so on. So I needed to make a development environment on my local machine and
push them to Lambda by:

```
zip -r hellolambda.zip *
aws lambda update-function-code --function-name HyosungVisitor --zip-file fileb://hellolambda.zip
```

fileb is AWS custom protocol and isn't a standard one.

I could connect to DynamoDB on my local environment without additional
parameters to DynamoDB client. ChatGPT said it is due to the creditals
file(~/.aws/credentials).

And I couldn't via API Gateway with an internal server error. So, I

- went to Configuration > Permission tab of Lambda
- clicked the role HyosungVisitor-role-1jxtca3i
- added AmazonDynamoDBFullAccess to that role

Just visiting the URL of API gateway using `fetch`, I could get the message from
the Lambda.

# 2025-08-10

I installed Arch on WSL.
https://wiki.archlinux.org/title/Install_Arch_Linux_on_WSL#Update_WSL

```
wsl --update
wsl --install archlinux
```

It simply gave me a shell prompt with a root account. I should start with
creating a user. `adduser` is not installed. So I ran `useradd`, `passwd`, and
`usermod`.


```
# Create an user 'taemin' with the home directory and a group with the same name as the user.
useradd -m -U -s /bin/bash taemin

passwd taemin

# Add 'taemin' in wheel group. The name 'wheel' came from 'big wheel' which means 'important people'.
usermod -a -G wheel taemin
```
I needed to append the following snippet to /etc/wsl.conf to log in as taemin.
https://wiki.archlinux.org/title/Install_Arch_Linux_on_WSL#Set_default_user

```
[user]
default=taemin
```

But, When I opened a new terminal tab it still logged in as root. I needed to terminate archlinux.

```
wsl --terminate archlinux
```

After termination, I could log in as taemin.


To make enable to run sudo as taemin.

```
su

pacman -Sy vi

# Uncomment the line `%wheel ALL=(ALL:ALL) ALL` in /etc/sudoers.
```

I changed the locale to `en_US.UTF-8`, but arch complained that it couldn't find
the locale. I had to edit /etc/locale.gen, uncomment `en_US.UTF-8 UTF-8` and run
`sudo locale-gen`.


# 2025-07-29

I rebased master and dev branches just leaving the commit that removes calls to
Slack webhook.

Interestingly, payments.z-emotion.com/en/sign-up succeeded in sending
verification link, but failed with reset-password link. It seems like the same
thing goes with z-emotion.com. Plus, the CORS error has gone too.

# 2025-07-28

aws command line interface is a quite confusing at first grance. There are many
subcommands and some of them works under specific conditions. For example, most
subcommands are affected by the current region which is set by ~/.aws/config and
some of them require an option like --cluster or --task-definition instead of
position argument.

```
$ aws ecs list-services --cluster zwls-api-tokyo-cluster
{
    "serviceArns": [
        "arn:aws:ecs:ap-northeast-1:649282530217:service/zwls-api-tokyo-cluster/z-emotion-api-dev-service",
        "arn:aws:ecs:ap-northeast-1:649282530217:service/zwls-api-tokyo-cluster/z-emotion-api-production-service"
    ]
}

$ aws ecs list-tasks --cluster zwls-api-tokyo-cluster
{
    "taskArns": [
        "arn:aws:ecs:ap-northeast-1:649282530217:task/zwls-api-tokyo-cluster/2d0f61b86387434e96639a0b34951b9b",
        "arn:aws:ecs:ap-northeast-1:649282530217:task/zwls-api-tokyo-cluster/a0daae0a0bb74e9daa915507ca12023c"
    ]
}

$ aws ecs list-task-definition-families
{
    "families": [
        "elastic-TaskDefinition",
        "elastic-search-TaskDefinition",
        "z-emotion-admin-tokyo-TaskDefinition",
        "z-emotion-api-tokyo-TaskDefinition",
        "zwls-api-task-def",
        "zwls-api-tokyo-TaskDefinition"
    ]
}

$ aws ecs describe-task-definition --task-definition z-emotion-api-tokyo-TaskDefinition:664

{
    "taskDefinition": {
        "taskDefinitionArn": "arn:aws:ecs:ap-northeast-1:649282530217:task-definition/z-emotion-api-tokyo-TaskDefinition:664",
        "containerDefinitions": [...],
        ...
    }
}

$ aws ecs describe-services --services 'z-emotion-api-dev-service' --cluster zwls-api-tokyo-cluster
{
    "services": [
        {
            "serviceArn": "arn:aws:ecs:ap-northeast-1:649282530217:service/zwls-api-tokyo-cluster/z-emotion-api-dev-service",
            "serviceName": "z-emotion-api-dev-service",
            "clusterArn": "arn:aws:ecs:ap-northeast-1:649282530217:cluster/zwls-api-tokyo-cluster",
            ...
        }
        ...
    ],
    ...
}
```

By default, aws prints an output as json. You can change the output format by
setting `output` option in the profile file.

--------------------------------------------------------------------------------

I could create a s3 bucket and upload files into it.

```
$ aws s3api create-bucket --bucket zemotion-sandbox --region ap-northeast-1 --create-bucket-configuration LocationConstraint=ap-northeast-1

http://zemotion-sandbox.s3.amazonaws.com/

$ aws s3 sync . s3://zemotion-sandbox

upload: hyosung/images/style/HS25MA110/1.png to s3://zemotion-sandbox/hyosung/images/style/HS25MA110/1.png                                                                                                      upload: hyosung/images/style/HS25MA110/13.png to s3://zemotion-sandbox/hyosung/images/style/HS25MA110/13.png
...

$ aws s3api list-objects --bucket zemotion-sandbox

{
    "Contents": [
        {
            "Key": "hyosung/images/style/HS25MA110/0.png",
            "LastModified": "2025-07-28T07:34:54+00:00",
            "ETag": "\"ad9e5b3eeae682a6570fd7130150137f\"",
            "ChecksumAlgorithm": [
                "CRC64NVME"
            ],
            "ChecksumType": "FULL_OBJECT",
            "Size": 3825669,
            "StorageClass": "STANDARD",
            "Owner": {
                "DisplayName": "dhan",
                "ID": "7bff02c25536a84a735e87a3871bfde327fcac10b06829f66ee10cae77c8d95c"
            }
        },
        ...
    ]
}
```

# 2025-07-27

I copyied my AWS access key to WSL and olivine.

There are snap package for aws-cli but it doesn't support aws_completer. So I
decided to install it from source AWS provides. I could install it in my local
directory by giving -i and -b option like below:

```
aws/install -i ~/.local/aws-cli -b ~/.local/bin
```

# 2025-07-25

I found why the version string from /hello didn't match to `git describe master`.
When running `git describe` in GitHub Action, it gives `HEAD~` instead of
`HEAD`, `version=$(git describe --tags --match 'v*' --exclude '*-rc*' HEAD~)`.
I don't know why it does that way.

--------------------------------------------------------------------------------

I could fix 502 Bad Gateway error. I was inspecting the log by
`aws logs tail /ecs/z-emotion-api-tokyo-TaskDefinition`. And there was an error
message, like:

```
/usr/src/app/node_modules/@slack/webhook/dist/errors.js:36
    const error = errorWithCode(new Error(`An HTTP protocol error occurred: statusCode = ${original.response.status}`), ErrorCode.HTTPError);
                                ^
Error: An HTTP protocol error occurred: statusCode = 404
    at httpErrorWithOriginal (/usr/src/app/node_modules/@slack/webhook/dist/errors.js:36:33)
    at IncomingWebhook.send (/usr/src/app/node_modules/@slack/webhook/dist/IncomingWebhook.js:55:58)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async /usr/src/app/dist/apps/api/main.js:5878:13 {
  code: 'slack_webhook_http_error',
  original: Error: Request failed with status code 404
      at createError (/usr/src/app/node_modules/@slack/webhook/node_modules/axios/lib/core/createError.js:16:15)
      at settle (/usr/src/app/node_modules/@slack/webhook/node_modules/axios/lib/core/settle.js:17:12)
      at IncomingMessage.handleStreamEnd (/usr/src/app/node_modules/@slack/webhook/node_modules/axios/lib/adapters/http.js:269:11)
      at IncomingMessage.emit (node:events:536:35)
      at endReadableNT (node:internal/streams/readable:1698:12)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    config: {
      url: 'https://hooks.slack.com/services/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',
      method: 'post',
      data: '{"timeout":0,"attachments":[{"color":"#05bc79","blocks":[{"type":"section","text":{"type":"mrkdwn","text":"[production] You have a new request."}},
      {"type":"section","text":{"type":"mrkdwn","text":"*When:*\\nFri Jul 25 2025 08:35:49 GMT+0000 (Coordinated Universal Time)"}},
      {"type":"divider"},
      {"type":"section","fields":[{"type":"plain_text","text":"Type:\\n:baby::skin-tone-2: userCreated","emoji":true},
      {"type":"mrkdwn","text":"*fullname:*\\nKyle Brownlee"},
      {"type":"mrkdwn","text":"*email:*\\nkyle.hong+alias11@gmail.com"},
      {"type":"mrkdwn","text":"*company:*\\nnull"}
      ]}]}]}',
      headers: {
        Accept: 'application/json, text/plain, */*',
        'Content-Type': 'application/json',
        'User-Agent': '@slack:webhook/6.1.0 node/20.19.4 linux/5.10.238-234.956.amzn2.x86_64',
        'Content-Length': 570
      },
      proxy: false,
      baseURL: 'https://hooks.slack.com/services/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',
      transformRequest: [ [Function: transformRequest] ],
      transformResponse: [ [Function: transformResponse] ],
      timeout: 0,
      adapter: [Function: httpAdapter],
      xsrfCookieName: 'XSRF-TOKEN',
      xsrfHeaderName: 'X-XSRF-TOKEN',
      maxContentLength: -1,
      maxBodyLength: -1,
      maxRedirects: 0,
      validateStatus: [Function: validateStatus],
      transitional: {
        silentJSONParsing: true,
        forcedJSONParsing: true,
        clarifyTimeoutError: false
      }
    },
    ...
}
```

So I was thinking there was a try to send Slack nofications when new user sign
up and suddenly Slack stopped to support that web hook. I removed the Slack
notification code and 502 Bad gateway error had gone. But the server is still
failing to send verification emails.

# 2025-07-24

I ran localhost API server and call REST API to test the signup routine, but
nothing went wrong. Interestingly, the version strings from /hello didn't match
ones I got by `git describe`.

Versions:
prod/hello      v0.0.2-1495-g8f01cda6
dev/hello       v0.0.2-1493-gdb9e838b
master branch   v0.0.2-1498-g23f205d9
dev branch      v0.0.2-1494-g745d7d0b

I switched to db9e838b, the same commit as dev, and tried to signup, but it
failed. It doesn't look like commit matters. Something in infrastructure or
external services masterr, I guess.

---------------------------------------------------------------------

Docker Desktop ran into an unexpected WSL error. Here's the error message:

```
An unexpected error occurred while executing a WSL command.

Either shut down WSL down with wsl --shutdown, and/or reboot your machine.
You can also try reinstalling WSL and/or Docker Desktop.
If the issue persists, collect diagnostics and submit an issue.

running wsl-bootstrap: running WSL command wsl.exe C:\WINDOWS\System32\wsl.exe -d docker-desktop
-u root -e wsl-bootstrap run --base-image /c/Program Files/Docker/Docker/resources/docker-desktop.iso
--cli-iso /c/Program Files/Docker/Docker/resources/wsl/docker-wsl-cli.iso
--data-disk b675d3ed-7307-714d-8f0b-554606b681cd: getty: cmdline has console=hvc0 but does not exist in /etc/securetty;
will not be able to log in as root on this tty hvc0.
: exit status 1
```

As I reinstalled Docker Desktop, it looked like the issues has gone. But I don't
know it has been exactly resolved.

# 2025-07-23

Blair complained that she was not able to copy asset id by clicking the id link
in asset store. Actually, it works but she connected directly to S3 bucket via
http://z-backoffice-v2.s3-website.ap-northeast-2.amazonaws.com/login, not
https://di6vhzh0u9tr9.cloudfront.net/login.

[Clipboard API](https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Interact_with_the_clipboard#writing_to_the_clipboard)
only works on https. That's why she wasn't able to copy ids.

---------------------------------------------------------------------

when I tried to signup to z-emotion.com I got the following error and failed to sign up.


```
XHR POST https://api.z-emotion.com/prod/v2/user/signup CORS Missing Allow Origin


POST                https://api.z-emotion.com/prod/v2/user/signup
Status              502
Version             HTTP/2
Transferred         260 B (122 B size)
Referrer Policy     strict-origin-when-cross-origin
Request Priority    Highest
DNS                 ResolutionSystem

Response Headers
content-length      122
content-type        text/html
date                Wed, 23 Jul 2025 05:57:49 GMT
server              awselb/2.0
X-Firefox-Spdy      h2

Request Headers
Accept              application/json, text/plain, */*
Accept-Encoding     gzip, deflate, br, zstd
Accept-Language     en-US,en;q=0.5
Authorization       Bearer undefined
Connection          keep-alive
Content-Length      158
Content-Type        application/json
Host                api.z-emotion.com
Origin              https://z-emotion.com
Priority            u=0
Referer             https://z-emotion.com/
Sec-Fetch-Dest      empty
Sec-Fetch-Mode      cors
Sec-Fetch-Site      same-site
TE                  trailers
User-Agent          Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:140.0) Gecko/20100101 Firefox/140.0
withCredentials     true

Request

{
    "email":"nq2f6ebm6@mozmail.com",
    "password": ***********,
    "firstname":"Why do",
    "lastname":"you want",
    "company":"know my name?",
    "loginType":"credentials"
}

Response
<html>
<head><title>502 Bad Gateway</title></head>
<body>
<center><h1>502 Bad Gateway</h1></center>
</body>
</html>


Cross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at https://api.z-emotion.com/prod/v2/user/signup.
(Reason: CORS header ‘Access-Control-Allow-Origin’ missing). Status code: 502.
```

# 2025-07-22

I ran `npm run build` in Vitarelax directory on WSL and I got out of memory
error.

```
  FATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory
```

I could solve this memory issue by [setting NODE_OPTIONS environment
variable](https://stackoverflow.com/a/59572966).

And I found that there are two versions of Babylon.js in Vitarelax project. The
one is Wumia's and the others Vitarelax's. Actually, Vitarelax has nothing to do
with Babylon.js directly. It made me think about the different behaviors on
Windows and WSL. For some reason, it looked like `npm run dev` on WSL selected
the wrong version of Babylon.js. I removed the dependency of Vitarelax on
Babylon.js to verify my guess. And yes. It worked as I remove the dependency.

------------------------------------------------------------------------------

When I was creating the EC2 instance, I only allowed firewall to except traffics
from my IP. That's why AWS Connect didn't work. I could modify that setting by
editing security group assigned to the instance.

-------------------------------------------------------------------------------

I installed nginx on the instance and I could connect to it(15.164.213.38) using a web broswer.

# 2025-07-21

I installed nginx on WSL. I could connect to localhost using a web browser.

--------------------------------------------------------------------------------

I created an EC2 instance, but I could connect to it via SSH
(ubuntu@15.164.213.38), but Amazon Connect didn't work. ChatGPT said I need to
apply a role to the instance and I followed the guideline, but it didn't work.

# 2025-07-20

15 July, I tried to debug a Razor app in WSL from VSCode, but it didn't work. I
still don't know why. So I installed dotnet SDK and created a console app on
Windows. And then install C# Dev Kit for VS Code. At first, I couldn't debugging
it. It complains that dotnet is not recognized as an internal or external
command. After close and relaunching all VS Code instances, it suddenly worked.

I did the same thing one more time, but instead I created a console app from
WSL. I could debug it from VS Code as well. After all I could debug my Razor
app. I don't know what made it impossible to debug and what made it possible
again. Maybe it's just about the order of plugin installation or PATH problem.

# 2025-07-17

I had to check if there are mismatches between our database and the excel file Audaces gave us.
We don't have web UI to check it so I need to run SQL manually. 4 people were missing from the Audaces team.

# 2025-07-16

I had to build a 360 panorama showroom demo for Hyosung. I decided to use [Photo
Sphere Viewer](https://photo-sphere-viewer.js.org/). I got started from a demo
it provided. It just uses script tags instead of NPM packages. I could've
changed it to get built by vite, but I thought I had no time to setup. I don't
know if it was the right decision.

# 2025-07-15

I tried to run Vitarelax in WSL. I feteched the source, initialize, and update
Wumia. `npm run dev` seemed to work, but I got a runtime error when I opened a
model page.

```typescript wumia-core.ts
this.props.noSkybox = this.props.noBg || this.props.noSkybox;
// console.log("Wumia", "version", import.meta.env.VITE_APP_VERSION);
this.engine = scene.getEngine() as Engine;
this.canvas = this.engine.getRenderingCanvas()!;
scene.createDefaultCamera(true, true, true); // createDefaultCamera is undefined!
```

I don't know why the behavior is different from when I run it on Windows. Maybe
there are some other project have the same issue, I guess.

---------------------------------------------------------------

I installed WSL extension for VSCode, ran `code .` in WSL, and got the following
message.

```
Installing VS Code Server for Linux x64 (cb0c47c0cfaad0757385834bd89d410c78a856c0)
Downloading: 100%
Unpacking: 100%
Unpacked 2050 files and folders to /home/kyle/.vscode-server/bin/cb0c47c0cfaad0757385834bd89d410c78a856c0.
Looking for compatibility check script at /home/kyle/.vscode-server/bin/cb0c47c0cfaad0757385834bd89d410c78a856c0/bin/helpers/check-requirements.sh
Running compatibility check script
Compatibility check successful (0)
```

VSCode opened and there was a WSL indicator at lower left corner. I could
navigate files and open a terminal just like I was in WSL. I could access files
in WSL from File Explorer by going `\\wsl.localhost\`.

# 2025-07-13


This's the table I could use when ssh-ing.

| Instance                      | Credential         | User     | IP             |
| ----------------------------- | ------------------ | -------- | -------------- |
| zelus-ci-linux-1              | zelus-ci-linux.pem | ubuntu   | 3.35.165.240   |
| zelus-ci-linux-2              | zelus-ci-linux.pem | ubuntu   | 3.38.137.232   |
| zelus-ci-linux-3 (CUDA)       | zelus-ci-linux.pem | ubuntu   | 3.38.111.252   |
| ssh-tunnel-ze-db              | zw-license-key.pem | ec2-user | 3.36.83.177    |
| zwls-prod-seoul-vpc-vpn       | zw-license-key.pem | ec2-user | 13.124.100.90  |
| zwls-prod-tokyo-vpc-vpn       | zw-license-key.pem | ec2-user | 13.113.226.89  |
| elastic-search-kibana-tokyo   | zw-license-key.pem | ec2-user | 13.115.161.148 |
| elastic-search-kibana-tokyo   | zw-license-key.pem | ec2-user | 13.115.161.148 |
| ssh-tunnel-pixel-db           | z-pixel            | ubuntu   | 13.125.228.208 |

I couldn't connect to ssh-tunnel-pixel-db with z-pixel.pem that was downloaded
from [notion page](https://www.notion.so/zemotion/keys-e066d9ce81c14129a97ce9bd52654e0f).


`ssh -i ~/secrets/z-pixel.pem ec2-user@13.125.228.208` didn't work with an error
message `ec2-user@13.125.228.208: Permission denied (publickey).` So I wanted to
check if the z-pixel.pem was actually came from AWS. To verify it I needed to
check the fingerprint of it.

```bash
# AWS dashboard says fingerprint is a6:9a:db:93:e4:50:39:98:b6:7f:6b:67:f2:ba:24:26:0a:f0:69:75
ssh-keygen -yf ~/secrets/z-pixel.pem >~/secrets/z-pixel.pub
# This prints 2048 MD5:b3:b5:e7:a1:17:45:a9:4b:15:7e:75:2b:f1:38:48:17 no comment (RSA)
ssh-keygen -lf ~/secrets/z-pixel.pem -E MD5
```

[Stackoverflow](https://serverfault.com/a/603983) says there are at least two
ways of generating fingerprints, 1) ssh-keygen and 2) openssl. And AWS
distingishes keys that are imported from local machines and are generated from
AWS console. AWS generates the SHA1 fingerprint from the private key if they are
generated from AWS. So I ran the following command.

```bash
# This prints SHA1(stdin)= a6:9a:db:93:e4:50:39:98:b6:7f:6b:67:f2:ba:24:26:0a:f0:69:75
openssl pkcs8 -in ~/secrets/z-pixel.pem -nocrypt -topk8 -outform DER | openssl sha1 -c
```

Here's [the official guide](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/verify-keys.html)
to verify the fingerprint.

It exactly matches the one on the dashboard. The key was right, but the user
name was not. `ubuntu` was the right user name for ssh-tunnel-pixel-db.

# 2025-07-21

I learned how to implement dependent dropdown lists in Google Spreadsheet. It
makes use of FILTER and TRANSPOSE function and data validation rules.
Interestingly, a formula in a cell can set values of other cells. It is not
limited to change its own value. And I could make use of it while creating a
dependent dropdown.

# 2025-07-11

I changed the measurement.json format to make it possible to insert additional
anchors into the scene without modifying glb files.

-----------------------------------------------------------------

I run docker as root from z-vto directory.
`docker run -v ".:/workspace" -p "8080:8080" --gpus all -it 54b94ee24e0c`.

To install dependencies I ran `python -m pip install -r requirements.txt`, but I
got following errors:

```
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed.
This behaviour is the source of the following dependency conflicts.
bentoml 1.2.19 requires nvidia-ml-py<12, but you have nvidia-ml-py 12.575.51 which is incompatible.
sagemaker 2.233.0 requires cloudpickle==2.2.1, but you have cloudpickle 3.0.0 which is incompatible.
```

I ignored the error and run `python run_gradio_union.py` Python couldn't find
detectron2 module. It turned out that detectron2 and annotator was broken links.
I should remove them and copy the directory from NAS. After copying files. I can
run pip without errors, but_gradio_union.py gave another error.

```
FileNotFoundError: [Errno 2] No such file or directory:
'/home/nas4_user/jeonghokim/Hoeyeong_Jin/VITON/Z-emotion-project/z-vto/logs/best_checkpoints/20241030_DCupper_DClower_DCdress_agnoffihand_agnoffiv9hand_rand dilate_gpt4ov6v12_jointcond_nopose_noip_intermcloth_resumev3v7_180kiter/checkpoint-240000_0.0330/pytorch_model.bin'
```

I couldn't find the directory in NAS. So I replace it with
`./logs/z-emotion-man/checkpoint-1200_0.0504/pytorch_model.bin` instead. It
worked after replacing the path.


# 2025-07-10

I added my account to docker group by `usermode -a -G docker $USER` in olivine,
but groups doesn't tell that I'm in the docker group even thought /etc/group
tells it is. Apperently `usermod` doesn't affect the current session, so I
logged out and in and it worked as expected.

After pulling an image I tried to run a container by
`docker run -v ".:/workspace" -p "8080:8080" --gpus all -it <image-id>`, but I
got an error like below.

```
docker: Error response from daemon: could not select device driver "" with capabilities: [[gpu]].
```

[Installing the nVidia Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html)

```bash
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
```

`apt search nvidia-container-toolkit` might list nvidia packages. Even though
systemctl says nvidia-powerd.service was loaded but failed to run, no need to
worry. It is for specific Optimus-based laptops and if your system just uses
nVidia GPUs, it does nothing. You can disable it.


```bash
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

```

To run docker in rootless mode, [you need to install uidmap package](https://docs.docker.com/engine/security/rootless/).

```bash
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | \
    sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

sudo apt update
sudo install uidmap docker-ce-rootless-extras
```

`dockerd-rootless-setuptool.sh install` failed even though I gave `--force option`.
`journalctl --user -xeu docker.service` says:

```
Jul 10 13:14:49 olivine dockerd-rootless.sh[6127]: running with RootlessKit, but rootlesskit-docker-proxy not installed: exec: "rootlesskit-docker-proxy": executable file not found in $PATH
Jul 10 13:14:49 olivine dockerd-rootless.sh[6099]: [rootlesskit:child ] error: command [/usr/bin/dockerd-rootless.sh] exited: exit status 1
Jul 10 13:14:49 olivine dockerd-rootless.sh[6087]: [rootlesskit:parent] error: child exited: exit status 1
Jul 10 13:14:49 olivine systemd[3194]: docker.service: Main process exited, code=exited, status=1/FAILURE
```

rootlesskit-docker-proxy was indeed not found. I think I'd better run docker as
root and test z-vto for now and run rootless later.


# 2025-07-09

I needed to copy files in the NAS to linux machine. I could mount SMB share to
my local directory by
`sudo mount -t cifs -o credentials=~/.smbcredentials //<ip-address>/<directory> <mount-point>`.
[I needed to install cifs-utils before mounting](https://askubuntu.com/a/923428).

# 2025-07-08

Vitarelax doesn't version control sofa and fabric files. They are consist of
glb, png, and other binary files. I decided to add them to Git for better
collaboration experience. It takes up a lot of space but it's not that huge that
Git can't control.

# 2025-07-02

I found that lb means a load balancer, but I can't remember where it was used
and why I was curious about it.

# 2025-07-01

I took a look at what EC2 instances was there and what key they was using.
Here's a list of them.

```
ap-northeast-2
Id                                                Key Name            Key Created Date                        Key Id                Public IP       Working
i-00f4630754249128e (zwls-prod-seoul-vpc-vpn)     zw-license-key      2021/01/27 29:38:...:8a:60             key-07f8b708c200109b8 13.124.100.90    Yes
i-09d4166421a56e775 (ssh-tunnel-ze-db)            zw-license-key      2021/01/27 29:38:...:8a:60             key-07f8b708c200109b8 3.36.83.177      Yes
i-01b16fa0d4081cdda (zelus-ci-windows-1)          zelus-ci-windows    2022/07/13 5c:a3:...:4f:96:84:7a:07:28 key-0f098a158d7ad08cb 52.78.15.171     Yes
i-0f286f84cf956ed46 (zelus-ci-linux-2)            zelus-ci-windows    2022/07/13 5c:a3:...:4f:96:84:7a:07:28 key-0f098a158d7ad08cb 3.38.137.232     Yes
                                                  zelus-ci            2022/07/12 7a:95:...:0d:47:88:7e:09:2a key-0f39e9a6b18581daf
i-0a58e23b4aa4161f6 (zelus-ci-linux-1)            zelus-ci-windows    2022/07/13 5c:a3:...:4f:96:84:7a:07:28 key-0f098a158d7ad08cb 3.35.165.240     Yes
                                                  zelus-ci            2022/07/12 7a:95:...:0d:47:88:7e:09:2a key-0f39e9a6b18581daf
i-00c284f8510d2d952 (zelus-ci-linux-3 (CUDA))     zelus-ci-windows    2022/07/13 5c:a3:...:4f:96:84:7a:07:28 key-0f098a158d7ad08cb 3.38.111.252     Yes
                                                  zelus-ci            2022/07/12 7a:95:...:0d:47:88:7e:09:2a key-0f39e9a6b18581daf
i-0119b08adf309e453 (ssh-tunnel-pixel-db)         z-pixel             2023/10/23 a6:9a:...:24:26:0a:f0:69:75 key-0648ad85a63f288ff 13.125.228.208   Yes
i-04c372f5d6c3a4047 (prometheus-runner)           general-ec2-key     2024/06/24 3a:55:...:89:11:66:8e:bf:22 key-0bab30d0c01b5f656 -                No
i-06697a9e98862806f (znest-api)                   cred-znest-window   2024/09/05 fb:d9:...:05:4c:66:67:36:65 key-0c5ba086cb62f201f -                No
i-0407f18850e213ceb (apg-pdf-handler)             apg-pdf-test-server 2024/09/03 6d:68:...:1d:4e:8b:b3:3a:9c key-0efb5336d5581636f -                No
i-01ee5e8663eea5e5f (zstudio-be)                  zstudio-be          2024/08/27 8e:d9:...:84:90:9f:81:9a:70 key-041de7c2501dc0c88 -                No
i-0743d0ff992646258 (z-virtual)                   z-virtual           2024/11/22 e7:b4:...:0b:47:b4:99:9e:6e key-0e523d6a8f3993fa2 54.180.57.152    No
i-05c07c86465fd9ec9                               z-pixel             2023/10/23 a6:9a:...:24:26:0a:f0:69:75 key-0648ad85a63f288ff -                No

ap-northest-1
Id                                                Key Name            Key Created Date                       Key Id                Public IP
i-0c98c7c727d93540c (zwls-prod-tokyo-vpc-vpn)     zw-license-key      2021/08/17 29:38:...:df:d4:f1:72:8a:60 key-0e07798a956b7d0af 13.113.226.89    Yes
i-07db139c64a35af45 (elastic-search-kibana-tokyo) zw-license-key      2021/08/17 29:38:...:df:d4:f1:72:8a:60 key-0e07798a956b7d0af 13.115.161.148   Yes

eu-west-3
i-0880b9b3fb210583e (vpc-test-server)             zw-license-key      2021/03/03 29:38:...:df:d4:f1:72:8a:60 key-0c5751dd7cca3ab1d -                No
i-07e4cac8522021aa1 (zwls-prod-paris-vpn)         zw-license-key      2021/03/03 29:38:...:df:d4:f1:72:8a:60 key-0c5751dd7cca3ab1d 35.181.74.247    No
```

I couldn't find zelus-ci.pem, zels-ci-windows.pem, cred-znes-window.pem, and
apg-pdf-test-server.pem. It looked like zelus-ci.pem is the same as
zelus-ci-linux.pem which I found in
[Slack](https://z-emotion.slack.com/archives/GHKQ0TCHL/p1750380062888119?thread_ts=1750379960.954099&cid=GHKQ0TCHL).

Hugo said that i-06697a9e98862806f (znest-api) and i-04c372f5d6c3a4047
(prometheus-runner) are not used any more. So I can ignore the keys I guess.

[This notion page](https://www.notion.so/zemotion/keys-e066d9ce81c14129a97ce9bd52654e0f)
contains several keys.

# 2025-06-30

I compared images that was rendered in a low resolution and resized from the
higher resolution. Resized ones are better. So we decided to use resized
versions and I made a shell script to generate images from the original images.
You can see the difference between them by comparing normal.png and resize.png.
You can find the script in https://github.com/kyle-ze/hyo.

--------------------------------------------------------------------------------

Install WSL ubuntu by `wsl --install Ubuntu`.

Install Docker.destktop from https://www.docker.com/products/docker-desktop/

Run Docker.destop and enable WSL integration otherwise you can't access docker from WSL.
    - Click the gear button on the top right corner of docker.desktop
    - Go to Resouces > WSL integration
    - Enable integration with distro
    - Click 'Apply & restart' at the bottom right
    - shutdown WSL if you're running WSL by `wsl --shutdown`.

Run `group` in WSL. You will see that you are a member of docker group.
`docker ps` should show the list of containers without any error.

Go to the directory that contains the docker compose file and run `docker compose up`.
Run `mysql -h 127.0.0.1 -P 3306 -u root -p` in WSL. It should work.
You have to create a database called 'zemotiondb'. Run `CREATE DATABASE zemotiondb;`
You can also connect to the database using adminer. Connect to localhost:8080.
    - Server: db
    - Username: root
    - Password: <password>
    - Database zemotiondb
The root password is written in docker-compose.yml.

WSL setup

```Bash
# You need install nodejs and npm on WSL otherwise npm on windows will fail to install packages
sudo apt update # without updating the package list `apt install` might be not able to download nodejs and npm
sudo apt install nodejs npm
sudo apt install luit # optional

git clone git@github.com:z-emotion/cloud-ze-frontend.git
git clone git@github.com:z-emotion/cloud-ze-api.git
git clone git@github.com:z-emotion/cloud-ze-backoffice.git
# And run npm install for each directory.

# Copy .env.local to cloud-ze-api
# The root password must be the same as written in cloud-zs-api/.env.local.

# Copy .env to cloud-ze-frontend

# Copy .env to cloud-ze-backoffice

# Install packages
(cd cloud-ze-api && npm install)
(cd cloud-ze-front && npm install)
(cd cloud-ze-backoffice && npm install)

cd cloud-ze-api && npm run start:dev
cd cloud-ze-frontend && npm run dev
cd clied-ze-backoffice && npm run dev
```

Connect to localhost:3000 and see if you can sign up. Now you can see the record
for your account in the database. Change the value of status field to ACTIVE
from READY. Because we can't send a verification mail from localhost. You should
be able to login in with the account you just created.

Change the value of role to ADMIN from USER. Go to backoffice page and login in
with your account. Try to create an account and see if it works.

z-emotion admin page (backoffice) https://di6vhzh0u9tr9.cloudfront.net/

You don't use Docker images that was used is development environment (redis,
mysql, admine, and etc) in production. In production, your application just
accesses to Amazon RDS and ElasticCache. So no docker compose files are need.


In local machine:

Run dockernized mysql server by
`docker run --name mysql-container -e MYSQL_ROOT_PASSWORD=love -d -p 3306:3306 mysql:latest`.
Run `npm run start:dev` in cloud-ze-api directory. It should say "No errors
found" and wait for requests at port 3952. Run `npm run dev` in
cloud-ze-frontend directory. It should say "event - compiled client and server
successfully in 298 ms (668 modules)" and wait for requests at port 3000. You
can open http://localhost:3000.

Backoffice is an adiminstrative site. You can manage users in this site.

- z-emotion admin page (backoffice) https://di6vhzh0u9tr9.cloudfront.net/

# 2025-06-26

Vitarelax project uses aws cli for publishing. So you have to install and
configure it. Just like github cli, aws cli also requires access keys for
security. You can create a access keys following the guide below:
https://docs.aws.amazon.com/IAM/latest/UserGuide/id-credentials-access-keys-update.html#rotating_access_keys_console
You have to save it right after creating it. There's no chance to see it next
time. aws configure will ask your access key and save it to ~/.aws/credential.

# 2025-06-25

Docker.zip Hugo gave to me was a collection of Docker compose files. I opened
that directory with Visual Studio

I couldn't upload Hyosung asset to S3 bucket because I was logged in as
asset-manager which doesn't have a permission. I logged in as kyle which Hugo
created for me and now I'm able to upload files. The root account (id:
649282530217) is shared by all members and each employee has their own IAM user
account. In my case it is kyle. I overrited the files in `/v1/style/test` in S3
and I needed to invalidate cloudfront cache for user to see the changes.

# 2025-06-24

Git for Windows v2.47.0.windows.1 hangs while cloning a repository via SSH.
This issue was resolved in v2.47.0.windows.2.
https://github.com/git-for-windows/git/issues/5199

Git for Windows v2.50.0.windows.1 also hangs while cloning, but apparently it is
a different bug https://github.com/git-for-windows/git/issues/5688
